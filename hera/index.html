<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="HERA: Hybrid Explicit Representation for Ultra-Realistic Head Avatars">
  <meta name="keywords" content="Head Avatar Modeling, Animatable Avatar, Primitive based Rendering, Novel View Synthesis">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>HERA</title>

  <!-- Bootstrap -->
  <link href="static/css/bootstrap-4.4.1.css" rel="stylesheet">
  
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <script type="module" src="https://unpkg.com/@google/model-viewer/dist/model-viewer.min.js"></script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h2 class="title is-2 publication-title" style="margin-top: 0; margin-bottom: 0">HERA: Hybrid Explicit Representation</h2>
          <h2 class="title is-2 publication-title" style="margin-top: 0">for Ultra-Realistic Head Avatars</h2>
          <h2 class="title is-4 publication-title" style="color:#6e6e6e;margin-top: 2; margin-bottom: 2">CVPR 2025</h2>

          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://rainbowrui.github.io/">Hongrui Cai</a><sup>1*</sup></span>&nbsp;&nbsp;&nbsp;&nbsp;
            <span class="author-block">
              <a href="https://scholar.google.com/citations?hl=zh-CN&user=AioOVwEAAAAJ">Yuting Xiao</a><sup>2*</sup></span>&nbsp;&nbsp;&nbsp;&nbsp;
            <span class="author-block">
              <a href="https://xuanwangvc.github.io/">Xuan Wang</a><sup>3†</sup></span>&nbsp;&nbsp;&nbsp;&nbsp;
            <span class="author-block">
              <a href="https://openreview.net/profile?id=~Jiafei_Li2">Jiafei Li</a><sup>3</sup></span>&nbsp;&nbsp;&nbsp;&nbsp;
            <span class="author-block">
              <a href="https://yudongguo.github.io/">Yudong Guo</a><sup>1</sup>&nbsp;&nbsp;&nbsp;&nbsp;
            <span class="author-block">
              <a href="https://sites.google.com/site/yanbofan0124/">Yanbo Fan</a><sup>4</sup>&nbsp;&nbsp;&nbsp;&nbsp;
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=fe-1v0MAAAAJ&hl=en">Shenghua Gao</a><sup>5</sup>&nbsp;&nbsp;&nbsp;&nbsp;
            <span class="author-block">
              <a href="http://staff.ustc.edu.cn/~juyong/">Juyong Zhang</a><sup>1†</sup>
            </span>
          </div>
          <br>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Science and Technology of China</span>&nbsp;&nbsp;&nbsp;&nbsp;
            <span class="author-block"><sup>2</sup>ShanghaiTech University</span>&nbsp;&nbsp;&nbsp;&nbsp;<br>
            <span class="author-block"><sup>3</sup>Xi’an Jiaotong University</span>&nbsp;&nbsp;&nbsp;&nbsp;
            <span class="author-block"><sup>4</sup>Nanjing University</span>&nbsp;&nbsp;&nbsp;&nbsp;
            <span class="author-block"><sup>5</sup>University of Hong Kong</span>&nbsp;&nbsp;&nbsp;&nbsp;
          </div>
          <br>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>*</sup>Equal contribution</span>&nbsp;&nbsp;&nbsp;&nbsp;
            <span class="author-block"><sup>†</sup>Corresponding authors</span>&nbsp;&nbsp;&nbsp;&nbsp;
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2403.11453"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- <span class="link-block">
                <a href="https://arxiv.org/pdf/2403.11453"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv fa-lg"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
              <!-- Dataset Link. -->
              <!--
              <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
              </span>
              -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <!--
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./resources/teaser.png"
                type="video/mp4">
      </video>
      -->
      <img src="https://raw.githubusercontent.com/RainbowRui/project_page_assets/master/hera/teaser.png" class="center">
      <h2 class="subtitle has-text-centered" style="margin-top: 15px">
        TL;DR: We propose a hybrid explicit representation for modeling ultra-realistic head avatars.
      </h2>
    </div>
  </div>
</section>

<!--
<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Reconstructions</h2>

        <div class="embed-responsive embed-responsive-16by9">

          <iframe style="clip-path: inset(1px 1px)" src="https://sketchfab.com/playlists/embed?collection=abee3cc1a7a7436c804f2bd3aadc2acd" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture; fullscreen" mozallowfullscreen="true" webkitallowfullscreen="true" width="100%" height="100%" frameborder="0"></iframe>
        </div>
        

      </div>
    </div>

  </div>
</section>

-->

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3" style="margin-top: -30px">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We introduce a novel approach to creating ultra-realistic head avatars and rendering them in real time 
            (≥ 30 fps at 2048 × 1334 resolution). First, we propose a hybrid explicit representation that combines 
            the advantages of two primitive based efficient rendering techniques. UV-mapped 3D mesh is utilized to 
            capture sharp and rich textures on smooth surfaces, while 3D Gaussian Splatting is employed to represent 
            complex geometric structures. In the pipeline of modeling an avatar, after tracking parametric models based 
            on captured multi-view RGB videos, our goal is to simultaneously optimize the texture and opacity map of mesh, 
            as well as a set of 3D Gaussian splats localized and rigged onto the mesh facets. Specifically, we perform 
            α-blending on the color and opacity values based on the merged and re-ordered z-buffer from the rasterization 
            results of mesh and 3DGS. This process involves the mesh and 3DGS adaptively fitting the captured visual information 
            to outline a high-fidelity digital avatar. To avoid artifacts caused by Gaussian splats crossing the mesh facets, 
            we design a stable hybrid depth sorting strategy. Experiments illustrate that our modeled results exceed those 
            of state-of-the-art approaches.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
    <!-- Paper video. -->
    <!--
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    -->
    <!--/ Paper video. -->
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">

    <!-- Method. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3" style="margin-top: -20px">Method</h2>

        <img src="https://raw.githubusercontent.com/RainbowRui/project_page_assets/master/hera/pipeline.png" class="center">
        <div class="content has-text-justified">
          <p style="margin-top: 30px">
            The overall pipeline of proposed HERA. In the canonical space, there is a mesh with a texture UV map 
            (visualized in RGB format) and an opacity UV map, along with several Gaussian splats defined in the 
            local coordinate system of the mesh facets. During animation, the positions of the mesh vertices change, 
            causing the rigged splats to move accordingly. Under the camera view, both the mesh and Gaussian splats 
            are rasterized using the proposed hybrid approach, and the image is rendered through α-blending. 
            The entire pipeline is fully differentiable. Guided by the captured image, the texture map and 
            the opacity map are optimized while the rigged Gaussian splats are updated and densified simultaneously.
          </p>
        </div>

      </div>
    </div>
    <!--/ Animation. -->

  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <!-- Hybrid Depth Sorting. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3" style="margin-top: -20px">Hybrid Depth Sorting</h2>

        <img src="https://raw.githubusercontent.com/RainbowRui/project_page_assets/master/hera/depth_sorting.png" class="center" width="50%" height="auto">
        <div class="content has-text-justified">
          <p style="margin-top: 30px">
            For sorting depths of different geometric primitives, we propose a strategy to prevent Gaussian splats 
            from crossing mesh facets. Instead of (a) sorting the depths of 3DGS (non per-pixel value) and mesh (per-pixel 
            value) directly, (b) we compare the depth of projected point and GS depth to sort stably.
          </p>
        </div>

      </div>
    </div>
    <!--/ Animation. -->

  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">

    <!-- Free Viewpoint Video. -->
    <div class="columns is-centered ">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered" style="margin-top: -30px">Free Viewpoint Video</h2>

        <div class="content has-text-justified">
          <p>
            Our HERA could render an avatar at a resolution of 2048 × 1334 with 
            a frame rate of approximately 81 FPS and achieves a PSNR of 34.0 ± 0.5 dB.
          </p>
        </div>
        
        <div class="content has-text-centered">
          <video id="replay-video"
                 autoplay
                 controls
                 muted
                 preload
                 playsinline
                 loop
                 width="100%">
            <source src="https://raw.githubusercontent.com/RainbowRui/project_page_assets/master/hera/demo.mp4"
                    type="video/mp4">
          </video>
        </div>

      </div>
    </div>

  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">

    <!-- Comparisons. -->
    <div class="columns is-centered ">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered" style="margin-top: -30px">Comparisons</h2>

        <div class="content has-text-justified">
          <p>
            We compare our HERA with state-of-the-art methods of animatable avatars.
          </p>
        </div>
        
        <h3 class="title is-4">Novel View sysnthesis</h3>
        <div class="content has-text-centered">
          <video id="replay-video"
                 autoplay
                 controls
                 muted
                 preload
                 playsinline
                 loop
                 width="100%">
            <source src="https://raw.githubusercontent.com/RainbowRui/project_page_assets/master/hera/nvs.mp4"
                    type="video/mp4">
          </video>
        </div>

        <h3 class="title is-4">Novel Expression Animation</h3>
        <div class="content has-text-centered">
          <video id="replay-video"
                 autoplay
                 controls
                 muted
                 preload
                 playsinline
                 loop
                 width="100%">
            <source src="https://raw.githubusercontent.com/RainbowRui/project_page_assets/master/hera/nea.mp4"
                    type="video/mp4">
          </video>
        </div>

      </div>
    </div>

  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">

    <!-- More Evaluations of Hybrid Representation. -->
    <div class="columns is-centered ">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered" style="margin-top: -30px">More Evaluations of Hybrid Representation</h2>

        <div class="content has-text-justified">
          <p>
            We conduct comparisons of our proposed hybrid representation on novel view synthesis in static scenes and dynamic scenes.
          </p>
        </div>
        
        <h3 class="title is-4">NVS in static scenes</h3>
        <div class="content has-text-centered">
          <img src="https://raw.githubusercontent.com/RainbowRui/project_page_assets/master/hera/static_scene.png" class="center">
        </div>

        <h3 class="title is-4">NVS in dynamic scenes</h3>
        <div class="content has-text-centered">
          <img src="https://raw.githubusercontent.com/RainbowRui/project_page_assets/master/hera/dynamic_scene.png" class="center">
        </div>

      </div>
    </div>

  </div>
</section>



<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    
    <div class="content has-text-justified">
      <p>
        If you find HERA useful for your work please cite:
      </p>
    </div>

    <pre><code>@inproceedings{Cai2025HERA,
  author    = {Hongrui Cai, Yuting Xiao, Xuan Wang, Jiafei Li, Yudong Guo, Yanbo Fan, Shenghua Gao, Juyong Zhang},
  title     = {HERA: Hybrid Explicit Representation for Ultra-Realistic Head Avatars},
  booktitle = {Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (CVPR)},
  year      = {2025}
}</code></pre>
  </div>
</section>



<section class="section" id="Acknowledgements">
  <div class="container is-max-desktop content">
    <h2 class="title">Acknowledgements</h2>
    This research was supported by the National Natural Science Foundation of China (No.62441224, No.62272433).
  </div>
</section>



<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
            This webpage template is from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>. 
            We sincerely thank <a href="https://keunhong.com/">Keunhong Park</a> for developing and open-sourcing this template.
          </p>
        </div>
      </div>
          <p></p>
        </div>
      </div>
</footer>

</body>
</html>
