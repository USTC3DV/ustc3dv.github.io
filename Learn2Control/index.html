<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Controlling Avatar Diffusion with Learnable Gaussian Embedding">
  <meta name="keywords" content="Diffusion, Control, Gaussian, Avatar">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Learn2Control</title>

  <!-- Bootstrap -->
  <link href="static/css/bootstrap-4.4.1.css" rel="stylesheet">
  
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <script type="module" src="https://unpkg.com/@google/model-viewer/dist/model-viewer.min.js"></script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered ">
          <span class="title is-2 publication-title" style="font-size: 70px">
            <span style="color: rgb(238, 41, 41);">Learn</span>2<span style="color: rgb(2, 135, 196);">Control</span>
          </span>
          <h2 class="title is-2 publication-title" style="margin-top: 0; margin-bottom: 2">Controlling Avatar Diffusion with Learnable Gaussian Embedding</h2>
            <!-- <h2 class="title is-4 publication-title" style="margin-top: 0; margin-bottom: 0">SIGGRAPH Asia 2022 (Journal Track)</h2> -->
          <!-- <h2 class="title is-4 publication-title" style="color:#6e6e6e;margin-top: 2; margin-bottom: 2">SIGGRAPH Asia 2022 (Journal Track)</h2> -->
          <!-- <h2 class="title is-2 publication-title" style="margin-top: 0"></h2> -->

          <div class="is-size-5 publication-authors">
            <span class="author-block"><a href="https://xuanghahahaha.github.io/">Xuan Gao</a></span>&nbsp;&nbsp;&nbsp;&nbsp;
            <span class="author-block">Jingtao Zhou</a></span>&nbsp;&nbsp;&nbsp;&nbsp;
            <span class="author-block">Dongyu Liu</a></span>&nbsp;&nbsp;&nbsp;&nbsp;
            <span class="author-block">Yuqi Zhou</a>
            </span>&nbsp;&nbsp;&nbsp;&nbsp;
            <span class="author-block">
              <a href="http://staff.ustc.edu.cn/~juyong/">Juyong Zhang</a>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">University of Science and Technology of China</span>&nbsp;&nbsp;&nbsp;&nbsp;
          </div>

          <div class="column has-text-centered">
            <div class="publication-links" style="margin-top: 0; margin-bottom: 2">
              <!-- PDF Link. -->
              <!--
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!--
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <!--
              <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
              </span>
              -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <!--
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="https://raw.githubusercontent.com/XuanGhahahaha/project_page_assets/master/Learn2Control/resources/teaser.png"
                type="video/mp4">
      </video>
      -->
      <img src="https://raw.githubusercontent.com/XuanGhahahaha/project_page_assets/master/Learn2Control/resources/teaser.png" class="center">
      <h2 class="subtitle has-text-centered" style="margin-top: 15px">
        TL;DR: We introduce a novel diffusion control signal representation splatted from learnable Gaussians, which is dense, adaptive, expressive, and 3D-consistent. Additionally, we incorporate a real/synthetic token to minimize artifact contamination of the synthetic dataset. Given a single reference image, our model can achieve high-quality, expressive, and consistent head generation.
      </h2>
    </div>
  </div>
</section>

<!--
<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Reconstructions</h2>

        <div class="embed-responsive embed-responsive-16by9">

          <iframe style="clip-path: inset(1px 1px)" src="https://sketchfab.com/playlists/embed?collection=abee3cc1a7a7436c804f2bd3aadc2acd" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture; fullscreen" mozallowfullscreen="true" webkitallowfullscreen="true" width="100%" height="100%" frameborder="0"></iframe>
        </div>
        

      </div>
    </div>

  </div>
</section>

-->

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths" style="width: 90%;">
        <h2 class="title is-3" style="margin-top: -30px">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Recent advances in diffusion models have made significant progress in digital human generation. However, most existing models still struggle to maintain 3D consistency, temporal coherence, and motion accuracy. A key reason for these shortcomings is the limited representation ability of commonly used control signals(e.g., landmarks, depth maps, etc.). In addition, the lack of diversity in identity and pose variations in public datasets further hinders progress in this area. In this paper, we analyze the shortcomings of current control signals and introduce a novel control signal representation that is optimizable, dense, expressive, and 3D consistent. Our method embeds a learnable neural Gaussian onto a parametric head surface, which greatly enhances the consistency and expressiveness of diffusion-based head models. Regarding the dataset, we synthesize a large-scale dataset with multiple poses and identities. In addition, we use real/synthetic labels to effectively distinguish real and synthetic data, minimizing the impact of imperfections in synthetic data on the generated head images. Extensive experiments show that our model outperforms existing methods in terms of realism, expressiveness, and 3D consistency.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
    <!-- Paper video. -->
    <!--
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    -->
    <!--/ Paper video. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <!-- Method. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3" style="margin-top: -20px">Motivation</h2>

        <div class="content has-text-centered">
          <video id="replay-video"
                 controls
                 preload
                 playsinline
                 loop
                 width="100%">
            <source src="https://raw.githubusercontent.com/XuanGhahahaha/project_page_assets/master/Learn2Control/resources/motivation.mp4"
                    type="video/mp4">
          </video>
        </div>

      </div>
    </div>
    <!--/ Animation. -->

  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <!-- Method. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-full-width">
        <h2 class="title is-3" style="margin-top: -20px">Method</h2>

        <img src="https://raw.githubusercontent.com/XuanGhahahaha/project_page_assets/master/Learn2Control/resources/pipe.png" class="center">
        <div class="content has-text-justified">
          <p style="margin-top: 30px">
            To address the limitations of existing public datasets in terms of identity diversity and pose richness, we propose to use synthetic data to improve the generalization ability and view consistency of the trained model. We first track the FLAME coefficients of the driving frames. Then the learnable Gaussians in UV space are transformed to 3D space according to FLAME UV mapping. Subsequently, the transformed Gaussians are projected and splatted to serve as control signals for a reference-guided diffusion model. 
          </p>
        </div>
        <div class="content has-text-centered">
          <video id="replay-video"
                 controls
                 preload
                 playsinline
                 loop
                 width="100%">
            <source src="https://raw.githubusercontent.com/XuanGhahahaha/project_page_assets/master/Learn2Control/resources/method.mp4"
                    type="video/mp4">
          </video>
        </div>

      </div>
    </div>
    <!--/ Animation. -->

  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">

    <!-- Results. -->
    <div class="columns is-centered ">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered" style="margin-top: -30px">Results</h2>

        <div class="content has-text-centered">
          <video id="replay-video"
                 controls
                 muted
                 preload
                 playsinline
                 loop
                 width="100%">
            <source src="https://raw.githubusercontent.com/XuanGhahahaha/project_page_assets/master/Learn2Control/resources/results.mp4"
                    type="video/mp4">
          </video>
        </div>

      </div>
    </div>

  </div>
</section>




<section class="section">
  <div class="container is-max-desktop">

    <!-- Ablation Studies. -->
    <div class="columns is-centered ">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered" style="margin-top: -30px">Novel View Synthesis</h2>

        <div class="content has-text-justified">
          <p>
            Given a single reference image, we manipulate the poses of the generated head images by adjusting the pose parameters of the FLAME head model. Our method produces reasonable and consistent results even for large pose variations. This demonstrates that our learnable Gaussian embedding, combined with training on a synthetic dataset, effectively enhances the 3D consistency of diffusion models.
          </p>
        </div>
        
        <div class="content has-text-centered">
          <video id="replay-video"
                 controls
                 muted
                 preload
                 playsinline
                 loop
                 width="100%">
            <source src="https://raw.githubusercontent.com/XuanGhahahaha/project_page_assets/master/Learn2Control/resources/nvs.mp4"
                    type="video/mp4">
          </video>
        </div>

      </div>
    </div>

  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <!-- Ablation Studies. -->
    <div class="columns is-centered ">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered" style="margin-top: -30px">Comparison</h2>

        <div class="content has-text-justified">
          <p>
            We compare our work with <a href="https://follow-your-emoji.github.io/">Follow-Your-Emoji</a>, <a href="https://xg-chu.site/project_gagavatar/">GAGAvatar</a>, <a href="https://yudeng.github.io/Portrait4D-v2/">GAGAvatar</a>, <a href="https://byteaigc.github.io/x-portrait/">X-Portrait</a>, <a href="https://p0lyfish.github.io/voodoo3d/">VOODOO 3D</a>, and <a href="https://samsunglabs.github.io/rome/">ROME</a>. Our method remarkably outperforms other methods in expressiveness and consistency.
          </p>
        </div>
        
        <div class="content has-text-centered">
          <video id="replay-video"
                 controls
                 muted
                 preload
                 playsinline
                 loop
                 width="100%">
            <source src="https://raw.githubusercontent.com/XuanGhahahaha/project_page_assets/master/Learn2Control/resources/comparison.mp4"
                    type="video/mp4">
          </video>
        </div>

      </div>
    </div>

  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <!-- Ablation Studies. -->
    <div class="columns is-centered ">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered" style="margin-top: -30px">Ablation Study</h2>
        Without training on our synthetic dataset, the model may fail to synthesize head images in large poses. If the model is trained without Real/Synthetic labels, the artifacts of the synthesized samples may influence the generated results.
        <div class="content has-text-centered">
          <video id="replay-video"
                 controls
                 muted
                 preload
                 playsinline
                 loop
                 width="100%">
            <source src="https://raw.githubusercontent.com/XuanGhahahaha/project_page_assets/master/Learn2Control/resources/ablation_data.mp4"
                    type="video/mp4">
          </video>
        </div>
        Some previous diffusion based portrait generation models employ landmarks, normal maps, or depth maps as signals to control diffusion generation, which often fails to accurately generate images that meet the required expressions and poses.
        This primarily stems from the sparsity of landmarks, as well as the low-frequency nature and 3D inconsistency of normal and depth information. Our learnable Gaussian feature map is a dense, adaptive, expressive, and 3D consistent control signal representation. It showcased better quality in controlling head motion generation.
        <div class="content has-text-centered">
          <video id="replay-video"
                 controls
                 muted
                 preload
                 playsinline
                 loop
                 width="100%">
            <source src="https://raw.githubusercontent.com/XuanGhahahaha/project_page_assets/master/Learn2Control/resources/ablation_explicit.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>

  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <div class="content has-text-justified">
      <p>
        If you find our paper useful for your work please cite:
      </p>
    </div>
    <pre><code>
      <!-- @article{Gao2022nerfblendshape,
         author = {Xuan Gao and Chenglai Zhong and Jun Xiang and Yang Hong and Yudong Guo and Juyong Zhang}, 
         title = {Reconstructing Personalized Semantic Facial NeRF Models From Monocular Video}, 
         journal = {ACM Transactions on Graphics (Proceedings of SIGGRAPH Asia)}, 
         volume = {41}, 
         number = {6}, 
         year = {2022}, 
         doi = {10.1145/3550454.3555501} } -->
    </code></pre>
  </div>
</section>



<section class="section" id="Acknowledgements">
  <div class="container is-max-desktop content">
    <h2 class="title">Acknowledgements</h2>
    <!-- This research was supported by the National Natural Science Foundation of China (No.62122071, No.62272433), and the Fundamental Research Funds for the Central Universities (No. WK3470000021). -->
  </div>
</section>



<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
            This webpage template is from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>. 
            We sincerely thank <a href="https://keunhong.com/">Keunhong Park</a> for developing and open-sourcing this template.
          </p>
        </div>
      </div>
          <p></p>
        </div>
      </div>
</footer>

</body>
</html>
